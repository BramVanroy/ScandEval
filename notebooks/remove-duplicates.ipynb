{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf65ae8-bae1-45b7-b45e-f62c06033efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb345f3-d90d-4eeb-bdce-448623fb3303",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_jsonl(path):\n",
    "    with Path(path).open() as f:\n",
    "        records = [json.loads(line) for line in f.readlines() if len(line) > 0]\n",
    "    df = pd.DataFrame.from_records(records)\n",
    "    return df\n",
    "\n",
    "def to_jsonl(df, path):\n",
    "    with Path(path).open('w') as f:\n",
    "        for record in df.to_dict('records'):\n",
    "            f.write(json.dumps(record))\n",
    "            f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c122c36b-c8f8-48ee-bdde-8c72ed51f07d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "datasets_dir = Path('datasets')\n",
    "for dataset_dir in datasets_dir.glob('[a-z_]*'):\n",
    "    \n",
    "    # Load dataset\n",
    "    train = read_jsonl(dataset_dir / 'train.jsonl')\n",
    "    test = read_jsonl(dataset_dir / 'test.jsonl')\n",
    "    \n",
    "    # Convert lists to tuples\n",
    "    for col in train.columns:\n",
    "        if isinstance(train.loc[0, col], list):\n",
    "            train[col] = train[col].map(tuple)\n",
    "            test[col] = test[col].map(tuple)\n",
    "            \n",
    "    # Drop duplicates within train/test\n",
    "    train = train.drop_duplicates().reset_index(drop=True)\n",
    "    test = test.drop_duplicates().reset_index(drop=True)\n",
    "    \n",
    "    # Get cross-duplicates\n",
    "    merged = pd.concat([train, test]).reset_index(drop=True)\n",
    "    not_xdups = [idx for idx in merged[~merged.duplicated(keep=False)].index.tolist()\n",
    "                 if idx in train.index]\n",
    "    \n",
    "    # Remove cross-duplicates\n",
    "    train = train.loc[not_xdups]\n",
    "    \n",
    "    #Â Double-check that all duplicates have been removed\n",
    "    new_merged = pd.concat([train, test]).reset_index(drop=True)\n",
    "    assert len(new_merged) == len(new_merged.drop_duplicates())\n",
    "    \n",
    "    # Store the new train and test sets\n",
    "    to_jsonl(train, dataset_dir / 'train.jsonl')\n",
    "    to_jsonl(test, dataset_dir / 'test.jsonl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
